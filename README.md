Risks of misinterpretation in the evaluation of Distant Supervision for Relation Extraction


Source code for paper: [Risks of misinterpretation in the evaluation of Distant Supervision for Relation Extraction.] (Accepted in SEPLN). The code is based on that developed by [Vashishth _et. al._ (2018)](https://github.com/malllabiisc/RESIDE). Includes implementation of [RESIDE](http://aclweb.org/anthology/D18-1157), [PCNN](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf), [PCNN+ATT](https://www.aclweb.org/anthology/P16-1200), [CNN](https://www.aclweb.org/anthology/C14-1220), CNN+ATT, and [BGWA](https://arxiv.org/pdf/1804.06987.pdf) models.

### Software dependencies

- Compatible with TensorFlow 1.x and Python 3.6
- Dependencies can be installed using `requirements.txt`.

### Dataset:

- We use [Riedel NYT](http://iesl.cs.umass.edu/riedel/ecml/) for train models.
 
- We built an test partition by selecting 324 instances of partition [Riedel NYT's](http://iesl.cs.umass.edu/riedel/ecml/) test partition. These instances have two labels, the ones generated [automatically (original labels)](https://drive.google.com/file/d/1Yb6bEOYC_qzvGcvDyv8nii-sU5QMdxZ8/view?usp=sharing) and the other generated by [manual revision](https://drive.google.com/file/d/1XUIUSLICh8Z7czxTJPsmzms2s3ibgUDq/view?usp=sharing).  

- We built an test partition based on [Riedel NYT's](http://iesl.cs.umass.edu/riedel/ecml/) test partition with all sentences where the relation is not NA. These instances have two labels, the ones generated [automatically (original labels)](https://drive.google.com/file/d/1eTeRmST5aTMItMVgmfAOPKXmzPEJVFTx/view?usp=sharing) and the other generated by [manual revision](https://drive.google.com/file/d/1wMMkiXk1okhDuXkDSs-15WLqTeuaZH69/view?usp=sharing) with Amazon Mechanical Turk.  


The structure of the processed input data is as follows.

  ```java
  {
      "voc2id":   {"w1": 0, "w2": 1, ...},
      "type2id":  {"type1": 0, "type2": 1 ...},
      "rel2id":   {"NA": 0, "/location/neighborhood/neighborhood_of": 1, ...}
      "max_pos": 123,
      "train": [
          {
              "X":        [[s1_w1, s1_w2, ...], [s2_w1, s2_w2, ...], ...],
              "Y":        [bag_label],
              "Pos1":     [[s1_p1_1, sent1_p1_2, ...], [s2_p1_1, s2_p1_2, ...], ...],
              "Pos2":     [[s1_p2_1, sent1_p2_2, ...], [s2_p2_1, s2_p2_2, ...], ...],
              "SubPos":   [s1_sub, s2_sub, ...],
              "ObjPos":   [s1_obj, s2_obj, ...],
              "SubType":  [s1_subType, s2_subType, ...],
              "ObjType":  [s1_objType, s2_objType, ...],
              "ProbY":    [[s1_rel_alias1, s1_rel_alias2, ...], [s2_rel_alias1, ... ], ...]
              "DepEdges": [[s1_dep_edges], [s2_dep_edges] ...]
          },
          {}, ...
      ],
      "test":  { same as "train"},
      "valid": { same as "train"},
  }
  ```

  * `voc2id` is the mapping of word to its id
  * `type2id` is the maping of entity type to its id.
  * `rel2id` is the mapping of relation to its id. 
  * `max_pos` is the maximum position to consider for positional embeddings.
  * Each entry of `train`, `test` and `valid` is a bag of sentences, where
    * `X` denotes the sentences in bag as the list of list of word indices.
    * `Y` is the relation expressed by the sentences in the bag.
    * `Pos1` and `Pos2` are position of each word in sentences wrt to target entity 1 and entity 2.
    * `SubPos` and `ObjPos` contains the position of the target entity 1 and entity 2 in each sentence.
    * `SubType` and `ObjType` contains the target entity 1 and entity 2 type information obtained from KG.
    * `ProbY` is the relation alias side information (refer paper) for the bag.
    * `DepEdges` is the edgelist of dependency parse for each sentence (required for GCN).

### Before train and test models
- Execute `setup.sh` for downloading GloVe embeddings.
- Download the dataset and copy into data directory.

### Training:
- For training **RESIDE** run:
  ```shell
  python reside.py -data ./data/riedel_train.pkl -name my_name
  ```
- For training **BGWA** run:
  ```shell
  python bgwa.py -data ./data/riedel_train.pkl -name my_name
  ```
- For training **PCNN** run:
  ```shell
  python pcnnatt.py -data ./data/riedel_train.pkl -name my_name -attn
  python pcnnatt.py -data ./data/riedel_train.pkl -name my_name
  ```
- For training **CNN** run:
  ```shell
  python cnnatt.py -data ./data/riedel_train.pkl -name my_name -attn
  python cnnatt.py -data ./data/riedel_train.pkl -name my_name
  ```
### Evaluation:
- For test **RESIDE** with _heuristic_ and _manual_ labels run:
  ```shell
    python reside.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval  (Manual labels)
    python reside.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original (Heuristic labels)
  ```

- For test **BGWA** with _heuristic_ and _manual_ labels run:
  ```shell
    python bgwa.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval  (Manual labels)
    python bgwa.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original (Heuristic labels)
  ```
- For test **PCNN** with _heuristic_ and _manual_ labels run:
  ```shell
    python pcnnatt.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval -attn (Manual labels)
    python pcnnatt.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original -attn (Heuristic labels)
    python pcnnatt.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval (Manual labels)
    python pcnnatt.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original (Heuristic labels)
  ```  
- For test **CNN** with _heuristic_ and _manual_ labels run:
  ```shell
    python cnnatt.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval -attn (Manual labels)
    python cnnatt.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original -attn (Heuristic labels)
    python cnnatt.py -data ./data/riedel_test_labeled_manually.pkl -name my_name -restore -only_eval (Manual labels)
    python cnnatt.py -data ./data/riedel_test_labeled_heuristic.pkl -name my_name -restore -only_eval -original (Heuristic labels)
  ```  
### Compute AUC for all trained models:
   ```shell
    python auc_heuristic_manual_labels.py    
  ```
Please check the names of the trained models.
For any clarification, comments, or suggestions please create an issue or contact [juanluis@inaoep.mx](https://github.com/juanluis17).

### Citation:
Please cite the following paper if you use this code in your work.
```bibtex
@inproceedings{reside2018,
  author = 	"Vashishth, Shikhar and 
  		Joshi, Rishabh and
		Prayaga, Sai Suman and
		Bhattacharyya, Chiranjib and
		Talukdar, Partha",
  title = 	"{RESIDE}: Improving Distantly-Supervised Neural Relation Extraction using Side Information",
  booktitle = 	"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
  month = 	oct # "-" # nov,
  address = 	"Brussels, Belgium",
  year = 	"2018",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"1257--1266",
  url = 	"http://aclweb.org/anthology/D18-1157"
}
```
